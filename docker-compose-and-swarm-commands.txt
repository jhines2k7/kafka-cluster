docker run \
--net=kafkanet \
--rm \
confluentinc/cp-kafka:4.0.0 \
kafka-topics --create --topic topic1 --partitions 3 --replication-factor 3 --if-not-exists --zookeeper zk1:22181,zk2:32181,zk3:42181

docker run \
--net=kafkanet \
--rm \
confluentinc/cp-kafka:4.0.0 \
kafka-topics --describe --topic topic1 --zookeeper zk1:22181,zk2:32181,zk3:42181

docker run \
--net=kafkanet \
--rm confluentinc/cp-kafka:4.0.0 \
bash -c "seq 42 | kafka-console-producer --broker-list kafka1:29092,kafka1:39092,kafka1:49092 --topic topic1 && echo 'Produced 42 messages.'"

docker run \
--net=kafkanet \
--rm \
confluentinc/cp-kafka:4.0.0 \
kafka-console-consumer --bootstrap-server kafka1:29092 --topic topic1 --new-consumer --from-beginning --max-messages 42

docker service create \
--network=kafkanet \
--name=schemaregistry \
-e SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zk1:22181 \
-e SCHEMA_REGISTRY_HOST_NAME=schemaregistry \
-e SCHEMA_REGISTRY_LISTENERS=http://0.0.0.0:8081 \
--constraint "engine.labels.node.type==confluence-platform" \
confluentinc/cp-schema-registry:4.0.0

docker run -it --net=kafkanet --rm confluentinc/cp-schema-registry:4.0.0 bash

/usr/bin/kafka-avro-console-producer --broker-list kafka1:29092,kafka2:39092,kafka3:39092 --topic schemademo --property schema.registry.url=http://schemaregistry:8081 --property value.schema='{"type":"record","name":"myrecord","fields":[{"name":"f1","type":"string"}]}'

{"f1": "value1"}
{"f1": "value2"}
{"f1": "value3"}

docker service create \
--network=kafkanet \
--name=kafkarest \
-e KAFKA_REST_ZOOKEEPER_CONNECT=zk1:22181 \
-e KAFKA_REST_LISTENERS=http://0.0.0.0:8082 \
-e KAFKA_REST_SCHEMA_REGISTRY_URL=http://schemaregistry:8081 \
-e KAFKA_REST_HOST_NAME=kafkarest \
--constraint "engine.labels.node.type==confluence-platform" \
confluentinc/cp-kafka-rest:4.0.0

docker run -it --net=kafkanet --rm confluentinc/cp-schema-registry:4.0.0 bash

curl -X POST -H "Content-Type: application/vnd.kafka.v1+json" \
--data '{"name": "my_consumer_instance", "format": "avro", "auto.offset.reset": "smallest"}' \
http://kafkarest:8082/consumers/my_avro_consumer

curl -X GET -H "Accept: application/vnd.kafka.avro.v1+json" \
http://kafkarest:8082/consumers/my_avro_consumer/instances/my_consumer_instance/topics/schemademo

curl http://kafkarest:8082/topics

docker service create \
--name=controlcenter \
--net=kafkanet \
--ulimit nofile=16384:16384 \
-p 9021:9021 \
-v /tmp/control-center/data:/var/lib/confluent-control-center \
-e CONTROL_CENTER_ZOOKEEPER_CONNECT=zk1:22181,zk2:32181,zk3:42181 \
-e CONTROL_CENTER_BOOTSTRAP_SERVERS=kafka1:29092,kafka2:39092,kafka3:49092 \
-e CONTROL_CENTER_REPLICATION_FACTOR=3 \
-e CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS=1 \
-e CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS=1 \
-e CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS=2 \
-e CONTROL_CENTER_CONNECT_CLUSTER=http://kafkaconnect:28082 \
confluentinc/cp-enterprise-control-center:4.0.0

docker run --rm -it --net=kafkanet -p 8000:8000 \
-e "KAFKA_REST_PROXY_URL=http://kafkarest:8082" \
-e "PROXY=true" \
landoop/kafka-topics-ui

docker service create \ 
-network=kafkanet \ 
-p 8000:8000 \
-e "KAFKA_REST_PROXY_URL=http://kafkarest:8082" \
-e "PROXY=true" \
landoop/kafka-topics-ui

docker run \
--net=kafkanet \
--rm \
confluentinc/cp-kafka:4.0.0 \
kafka-topics --create --topic quickstart-offsets --partitions 3 --replication-factor 3 --if-not-exists --zookeeper zk1:22181,zk2:32181,zk3:42181

docker run \
--net=kafkanet \
--rm \
confluentinc/cp-kafka:4.0.0 \
kafka-topics --create --topic quickstart-data --partitions 3 --replication-factor 3 --if-not-exists --zookeeper zk1:22181,zk2:32181,zk3:42181